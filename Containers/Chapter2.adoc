ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: images/


== Managing Containers with the New Runtime

=== Deploying Containers with the New Container Runtime

==== The Podman Container Engine

RHEL8 includes he *container-tools* package module. New engine is *podman* replaces *docker* and *moby*. It also contains new tools *buildah* to build container images and *skopeo* to manage images on registries like *runc*. The new toolset allows building/running containers without daemons.

image::containers-runtime-stacks.png[title="Docker to RHEL8 Container Runtime", align="center"]

*Container Runtime Toolset*

* Docker replaced with new container runtime
* New toolset supports OCI and reuse of third-party images
* Integrates with *audit* of Docker client-server model
* *container-tools* module provides new container runtime tools and engine.


image::containers-runtime-toolset.svg[title="New Container Runtime", align="center"]

*Describing new Container Runtime Tool*

* The *podman* engine is daemonless and supporting container execution.
* *podman* syntax is similar to the docker command, supporting *Dockerfile* use
* *Buildah* builds container images, from scratch or a Dockerfile.
* Copy and inspect container images in both local and remote container registries with *Skopeo*
* *Skopeo* supports Docker and private registries, the Atomic registry, and local directories, including those which use OCI

[TIP]
====
RHEL8 includes *Pacemaker* containers with *podman* as a tech preview. Pacemaker supports execution of the container across multiple hosts.
====

.Using Container Tools


.Installation of Container Tools
[source,bash]
----
[student@workstation ~]$ sudo yum module install container-tools
----

=== Podman Configuration Files

Depending on whether *podman* is being run as a privileged user or as a *rootless* user, the configuration file locations and directives will be difference.

==== Root-Based Podman

When running Podman as a privileged user, the default configurations are used. Generally these files are not modified, however, it is a common practice to modify the *registries.conf* file to add additional container image registries as well as alter the registry search order.

.Default Configuration Files
* */etc/containers/storage.conf* - Contains information about the default storage for Podman containers when using *podman* in a non-rootless fashion.
* */etc/containers/registries.conf* - Contains information about the registries used for *podman* when doing *podman search* and also for pulling/running of container images.
* */etc/cni/net.d/87-podman-bridge.conflist* - Contains information related to the CNI (container network interface) and IP configuration for the container networks.

==== Rootless Podman

When running *podman* in *rootless* mode, all configuration files will be based on user configurations and are located within the user's home directory.

.User-Based Podman Configuration Files
* */home/student/.config/containers/storage.conf*: Specifies storage configuration for Podman in *rootless* mode.
* */home/student/.config/containers/registries.conf*: Specifies registry configuration for Podman in *rootless* mode.


.Podman User Configuration Files
[IMPORTANT]
====
If the configuration files don't exist in the user's home directory, *podman* will default back up to */etc* for the configuration files and if they aren't there, it will fall back to the */usr/share/containers/* directory.
====


.Podman Configuration File Precedence
[TIP]
====
*podman* has multiple configuration file locations and the order of precedence depends on the if the files exist. Traditionally in a *rootless* implementation, the configuration files with be in the user's *$HOME/.config/containers* directory. In the case of networking, there is no CNI equivalent for *rootless* Podman as *rootless* containers rely on *SLIRP* for networking.

.*Containers.conf*
. *$HOME/.config/containers/containers.conf*
. */etc/containers/containers.conf*
. */usr/share/containers/containers.conf*

.Storage Configurations
. *$HOME/.config/containers/storage.conf*
. */etc/containers/storage.conf*

.Registry Configurations
. *HOME/.config/containers/registries.conf*
. */etc/containers/registries.d/*
. */etc/containers/registries.conf*

Precedence of *1* is the highest and will override all others.
====


.References
[NOTE]
====
* *Podman Project - Config Files and Tutorial*: https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md
* *Why can't I use sudo with rootless Podman?*: https://www.redhat.com/sysadmin/sudo-rootless-podman
* *What happens behind the scenes of a rootless Podman container?*: https://www.redhat.com/sysadmin/behind-scenes-podman
* *Rootless containers using Podman*: https://www.redhat.com/sysadmin/rootless-containers-podman
* *Container video series: Rootless containers, process separation, and OpenSCAP*: https://www.redhat.com/sysadmin/container-video-series (Really good by Brian Smith - Former RH TAM, now works in the RHEL Platform BU)
* *Why canâ€™t rootless Podman pull my image?*: https://www.redhat.com/sysadmin/rootless-podman
====


=== Container Image Storage

Containers use ephemeral storage for running containers which is an overlay filesystem with a new read/write (RW) layer added to the original container image. This ephemeral storage is removed once the container is removed from the system. Container images on the other-hand are stored locally on the system in the container image storage registry. It is important to know where the image storage is located for both container images and ephemeral storage for running containers so that it can be monitored for pro-active system administration and cleanup. The storage location for both container images and ephemeral storage is generally defined in the *storage.conf* file.

==== Root-Based Podman

A default installation of Red Hat Container Tools (podman) will create a configuration file for storage located */etc/containers/storage.conf*. These are the most likely settings to be used when running Podman as a *root* user.

.Default Storage Location
[source,bash]
----
[storage]

# Default Storage Driver
driver = "overlay"

# Temporary storage location
runroot = "/var/run/containers/storage"

# Primary Read/Write location of container storage
graphroot = "/var/lib/containers/storage"
----

There are plenty of options regarding containers and image storage, but the primary locations to monitor are */var/run/containers/storage* and */var/lib/containers/storage* as these will be the most used locations by *podman*.

==== Rootless Podman

Podman uses the storage configuration file located *$HOME/.config/containers/storage.conf*. These settings are used because the *overlay* filesystem must use a user-space filesystem overlay so it uses *FUSEFS* storage drives for the user-space filesystems.

.Default Storage Location for Rootless Podman
[source,bash]
----
[storage]
  driver = "overlay"
  runroot = "/run/user/1000"
  graphroot = "/home/student/.local/share/containers/storage" <1>
  [storage.options]

... OUTPUT OMITTED ...

    mount_program = "/usr/bin/fuse-overlayfs" <2>
----
<1> Image storage location
<2> FUSEFS Overlay Filesystem Driver

There are plenty of options regarding containers and image storage, but the primary locations to monitor are */var/run/containers/storage* and */var/lib/containers/storage* as these will be the most used locations by *podman*.


=== Container Networking

Podman is meant to provide all management of containers and the container runtime. Podman is capable of managing the container network (SDN) for root-based Podman containers. The CNI controls the specifications for networking and how the SDN is defined on the system. There is no SDN available for *Rootless* containers as *podman* implements networking for *Rootless* containers using *SLIRP*.

==== Root-Based Podman

Podman root-level containers can leverage CNI. The containers SDN network is defined in the */etc/cni/net.d/87-podman-bridge.conflist* configuration file. Containers can communicate to each other within the SDN on the same system.

.*/etc/cni/net.d/87-podman-bridge.conflist*
[source,json]
----
{
    "cniVersion": "0.4.0",
    "name": "podman",
    "plugins": [
	{
            "type": "bridge", <1>
            "bridge": "cni-podman0", <2>
            "isGateway": true,
            "ipMasq": true,
            "ipam": {
		"type": "host-local",
		"routes": [
		    {
			"dst": "0.0.0.0/0"
		    }
		],
		"ranges": [ <3>
		    [
			{
			    "subnet": "10.88.0.0/16",
			    "gateway": "10.88.0.1"
        }
  		    ]
  		]
              }
  	},
  	{
              "type": "portmap",
              "capabilities": {
  		"portMappings": true
              }
  	},
  	{
              "type": "firewall"
  	}
      ]
  }
----
<1> Defines network type as a *Bridge*
<2> Defines the network name for the bridge as *cni-podman0* for the container SDN
<3> Defines the network IP Address range for the container SDN

==== Rootless Podman

For *rootless* podman the networking for containers leverages *SLIRP*. This is provided by the *slirp4netns* package and provides user-mode networking and namespaces for the networks. Containers running as a *Rootless* container will not receive an IP address from the CNI SDN and cannot communicate with each other or the outside except by using and leveraging *port forwarding*.


.Red Hat Container Catalog
[NOTE]
====
*Red Hat Container Catalog*: https://catalog.redhat.com/software/containers/search
====

=== Managing Containers using the Red Hat Web Console

The Red Hat Web Management Console (Cockpit) can be used to manage container images as well as running containers. However, in order to manage some of the aspects around containers, certain configurations must already be in place.

Cockpit can almost manage the full container lifecycle. using the *Podman containers* plugin. Container images can be downloaded, managed, deleted. Containers can be launched from container images, stopped, restarted. Containers can even be analyzed providing runtime information, container logs, and even console access. Existing containers can also be turned into new container images using the *Commit* functions.

.Container Runtime Details

The *Details* tab can provide container runtime information. This is similar to running the *podman inspect* without providing all the details.

image::Chapter2-e877a.png[title="Container Runtime Information", align="center"]

.Container Logs

The *Logs* tab is capable of sharing the container logs. This is similar to running the *podman logs* command.

image::Chapter2-64e78.png[title="Container Logs", align="center"]

.Container Console

Cockpit also allows accessing a console directly inside the running container. Accessing the console via cockpit is the same as running the *podman exec -it <Container> /bin/bash* command.
+
image::Chapter2-416de.png[title="Container Console", align="center"]

==== Installing Cockpit Podman Plugins

In order to utilize Cockpit to manage containers with Podman there must be two things that are in place.

.Cockpit *podman* Requirements
* Podman cockpit plugins
* Podman service started and running on the system

. Install *cockpit-podman* Modules
+
.Installation of Cockpit *podman* Plugins
[source,bash]
----
[root@servera ~]# yum install cockpit-podman

... OUTPUT OMITTED ...

Complete!
[root@servera ~]#
----

. Enable *podman* Service in Cockpit
.. Sign into Cockpit
.. Click "*Podman containers*"
.. Click "*Start podman*"
+
image::Chapter2-c0656.png[title="Cockpit - Podman Containers (Setup)", align="center"]
+
image::Chapter2-89d80.png[title="Cockpit - Podman Containers (In-Use)", align="center"]
+
.Ensure Cockpit is both Installed and Enabled
[IMPORTANT]
====

.Installing Cockpit
[source,bash]
----
[root@servera ~]# yum install cockpit

... OUTPUT OMITTED ...

subscription-manager-cockpit-1.28.13-2.el8.noarch
tracer-common-0.7.5-2.el8.noarch

Complete!
----

.Enabling Cockpit Socket
[source,bash]
----
[root@servera ~]# systemctl enable cockpit.socket --now
Created symlink /etc/systemd/system/sockets.target.wants/cockpit.socket â†’ /usr/lib/systemd/system/cockpit.socket
----
====


==== Using Cockpit to Manage Containers

Once installed and enabled, the *Podman containers* plugin can begin managing containers and images. There are a few things to remember and consider as the *plugin* can't do everything.

.Plugin Considerations and Limitations
* *Registries*: Image registries must be setup and specified ahead of time in the */etc/containers/registries.conf* file.
** Image registries must be in the configuration file in order for images to be downloaded and used. If the configuration file is updated after the *podman* service has been started, the service must be "restarted" in order for Cockpit to see the changes.
** There are some difficulties with providing authentication information to registries as there isn't currently an interface to login to the registry within Cockpit.
* *Storage Volumes*: It might be necessary to have volumes and permissions setup to properly mount/map the volumes into the running containers

.Registry Credentials
[IMPORTANT]
====
In order for Podman to authenticate, you must provide credentials. There needs to be a config file and you may also need to login to *podman* from the command line.

.*.docker/config.json* Config File
[source,bash]
----
[student@servera ~]$ cat .docker/config.json
{
  "ServerURL": "https://registry.redhat.io/v1",
  "Username": "RHNID",
  "Secret": "RHNPassword"
}
----

.CLI Login
[source,bash]
----
[student@servera ~]$ podman login registry.redhat.io
Authenticating with existing credentials...
Existing credentials are valid. Already logged in to registry.redhat.io
----
====


.Container Image Management with Cockpit
====
. Navigate to the *Images* section and select *Get new image*
+
image::Chapter2-d266c.png[title="Cockpit - Podman Container Images", align="center"]
+
image::Chapter2-4b45a.png[title="Search for Images", align="center"]
. Select the registry to search, tags, and image name/description, then click "Download"
.. Search for the HTTPD-Parent image in the *quay.io* registry.
+
image::Chapter2-9e757.png[title="HTTPD 2.4 Parent Image from Red Hat Training - Quay.io", align="center"]
+
.Adding the *quay.io* Registry to */etc/containers/registries.conf*
[TIP]
=====
Update the *registries.conf* file and then restart the *podman* service.

.Edit */etc/containers/registries.conf*
[source,bash]
----
# To ensure compatibility with docker we've included docker.io in the default search list. However Red Hat
# does not curate, patch or maintain container images from the docker.io registry.
[registries.search]
registries = ['registry.access.redhat.com', 'registry.redhat.io', 'docker.io', 'quay.io']<1>
----
<1> Adding *quay.io*


.Restart *podman*
[source,bash]
----
[root@servera ~]# systemctl restart podman.service
----

=====
+
.Registry Authentication
[CAUTION]
=====
It is important to keep in mind, images requiring authentication to a registry will provide errors in Cockpit as you will be accessing the registry as an unauthenticated user.

image::Chapter2-5a3bb.png[title="Registry Authentication Issues", align="center"]

Based on timeline and platform difficulties, images downloaded in the Red Hat Web Management Console will be coming from public (unauthenticated) registries.
=====
. Confirm image was downloaded.
+
image::Chapter2-1bc27.png[title="Images in Local Registry", align="center"]

. Explore image details by clicking the *>* and expanding the available information.
+
image::Chapter2-fb988.png[title="HTTPD-Parent Image Details - Image Information", align="center"]
+
image::Chapter2-2fd80.png[title="Clair Image Details - Containers Using Image", align="center"]
====

.Container Management with Cockpit

It is possible to manage both *rootless* and *root-based* containers in Cockpit depending on the user you are using to access the management console. In order to create and launch new containers from Cockpit, the image must already be downloaded and existing in the local image registry.

.*Container Creation*
====
. Select the image to be used to launch the container by clicking the *Play* button.
+
image::Chapter2-cd516.png[title="HTTPD-Parent Image Selection", align="center"]
. Enter details you wish to use for your image and click "Run"
.. Container Name
.. Port mapping
.. Volume mapping
+
image::Chapter2-acd5b.png[title="Launcing a Demo Container", align="center"]
+
.*NOTE* Regarding *With terminal*
[WARNING]
=====
For several containers, you should *uncheck* the *_With terminal_* option as this could cause the container to exit unexpectedly.
=====
. Verify container was launched
+
image::Chapter2-8a097.png[title="Running Container Verification", align="center"]
+
image::Chapter2-4003d.png[title="Running Container Details", align="center"]

. Allow connection to container externally through Firewall
.. Click *Networking*
.. Click *Edit rules and zones* for the Firewall
+
image::Chapter2-4a197.png[title="Using Cockpit to Manage Firewalls", align="center"]

. Click *Add Services* and either select an existing service or create custom ports, then click the *Add Services* button on the *Add services to public zone*.
.. Verify the service was added
+
image::Chapter2-079f2.png[title="Add the HTTP Service", align="center"]
+
image::Chapter2-98f48.png[title="HTTP Service Available", align="center"]

. Verify the container is running and hosting the website via the console and through a web browser.
+
.Local Container Verification
[source,bash]
----
sh-4.4# curl localhost
Hello from the httpd-parent container!
sh-4.4#
----
+
image::Chapter2-6ee11.png[title="Container Console in Cockpit", align="center"]
+
image::Chapter2-70921.png[title="Application Verification in Firefox", align="center"]
====

.*Saving a Container Image from a Running Container*
====
. Select the container to use as a base for the image
.. Click *Commit*
+
image::Chapter2-376ab.png[title="Creating an new image from a container.", align="center"]

. Select and complete the *Commit image* form
.. Specify *Image name*
.. Other fields are optional
+
image::Chapter2-b93ab.png[title="Committing image", align="center"]
+
.Images from a Running Container
[TIP]
=====
It is possible to create images from running container. If the container is running, it will be paused briefly while the image is created.
=====

. Verify the image was created
+
image::Chapter2-97e74.png[title="Image Verification", align="center"]
+
.Image Tags
[IMPORTANT]
=====
If there is no tag specified when the image is being committed, *podman* will automatically add the *_latest_* tag to the image.
=====
====

.*Container Cleanup*
====
. Select the container to stop and remove.
.. If you just want to stop a running container, click *Stop*
.. To stop and remove the container, click the *Trashcan*
+
image::Chapter2-2506f.png[title="Container Cleanup", align="center"]
+
.Deleting a Running Container
[TIP]
=====
Running containers must be stopped before they can be deleted or removed. If a container is running, and you click the *Trashcan* it will stop and delete the container. This is similar to performing a *podman rm -f <Container>* as it will force stop and then remove the container.

image::Chapter2-606fd.png[title="Force Removing a Running Container", align="center"]
=====

====

===== Using Cockpit to Manage Containers (Rootless)

Just as Podman can manage containers as a "rootless" user, it is also possible to manage containers within Cockpit as a "rootless" user. All the same principles apply in Cockpit as they do with *podman*. Additionally, Cockpit has multiple options if the user happens to be in the *sudoers* file.

.Exploring Cockpit Containers as the *student* User
====
. Login to Cockpit as the Student user
+
image::Chapter2-068eb.png[title="Cockpit Student Login", align="center"]

. Navigate to the *Podman containers* section
+
image::Chapter2-4a213.png[title="Podman containers plugin", align="center"]

. Click *Start podman*
+
image::Chapter2-02c9f.png[title="Podman containers - Owner All View", align="center"]
+
image::Chapter2-0c745.png[title="Podman containers - Owner *student* View", align="center"]
+
image::Chapter2-26455.png[title="Podman containers - Owner *System* View", align="center"]
+
[IMPORTANT]
======
The *student* user is able to become root as it exists in the *sudoers* file. Based on Cockpit's abilities, the *student* user can see both containers and images owned by *student*, but it can also see containers and images owned by *system*.
======

====

Launching and managing containers is also performed the same way as the student user.

.Working with Containers in Cockpit as *student.
====

. Download a container image.
.. Registry: *registry.access.redhat.com*
.. Image: *ubi7*
+
image::Chapter2-df30d.png[title="UBI7 Image Download", align="center"]

. Launch a Container with the UBI7 Image
.. Container Name: ubi7-test
.. Image: *registry.access.redhat.com/ubi7/ubi:latest*
+
image::Chapter2-297ed.png[title="UBI7 Image - Local Repository", align="center"]
+
image::Chapter2-d3056.png[][title="UBI7 Container Launch Parameters", align="center"]

. Explore the *ubi7-test* Container
+
image::Chapter2-35cbc.png[title="UBI7 Container - Interactive Console", align="center"]

. Cleanup running Container (_force delete_)
+
image::Chapter2-f3100.png[title="UBI7 Container - Deletion", align="center"]


. Cleanup unneeded images
+
image::Chapter2-1b4f6.png[title="UBI7 Image - Deletion", align="center"]

. Verify both the container and image have been deleted
+
image::Chapter2-d83d0.png[title="Cleanup Successful", align="center"]
====


.References
[NOTE]
====

*Oracle Linux: Use Cockpit to Manage Podman Containers*: https://docs.oracle.com/en/operating-systems/oracle-linux/8/tutorial-cockpit-podman/#Before-You-Begin

*Managing your Podman containers with Cockpit on Fedora*: https://www.tutorialworks.com/podman-monitoring-cockpit-fedora/
====
